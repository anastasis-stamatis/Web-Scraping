{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data from website backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A website of ours provided export which did not include all the data of interest. As our developer had a huge backlog to complete, I decided to scrape the backend to get us the data we needed.<br>\n",
    "Links have been changed for anonymity purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Pandas display options\n",
    "pd.set_option('display.max_columns',6000)\n",
    "pd.set_option('display.max_rows',6000)\n",
    "\n",
    "# show all outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "# Insert a custom library for excel output\n",
    "sys.path.insert(1, '/Users/anastasis/Documents/Anastasis/Libraries')\n",
    "\n",
    "from lib_functions import write_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://user:pass@url.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get lists of records\n",
    "Each record was hosted on a different URL. So the first step was to get a hold of all the different records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_urls = []\n",
    "payment_urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "els = driver.find_elements_by_xpath('//*[@title=\"View Restaurant\"]')\n",
    "data_urls += [el.get_attribute('href') for el in els]\n",
    "ords = driver.find_elements_by_xpath('//*[@title=\"Orders\"]')\n",
    "payment_urls += [el.get_attribute('href') for el in ords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "281"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_urls)\n",
    "len(payment_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all the different htmls to a folder for later extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "281it [15:03,  3.21s/it]\n"
     ]
    }
   ],
   "source": [
    "for i,d in tqdm(enumerate(data_urls)):\n",
    "    driver.get(d)\n",
    "    \n",
    "    time.sleep(2)\n",
    "    source = driver.page_source\n",
    "    f = open('all_restaurants/'+str(i)+'.txt','w')\n",
    "    _=f.write(source)\n",
    "    _=f.close()\n",
    "    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import Select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Payments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for the payment urls - order details - but only if at least one order has been completed for the restaurant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "281it [06:14,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "for i,p in tqdm(enumerate(payment_urls)):\n",
    "    time.sleep(1)\n",
    "    driver.get(p)\n",
    "    \n",
    "    rest_id = p.split('/')[-1]\n",
    "    \n",
    "    if 'No items to display' not in driver.find_element_by_class_name('ajax_list').text:\n",
    "        Select(driver.find_element_by_class_name('per_page')).select_by_value('100')\n",
    "        time.sleep(2)\n",
    "\n",
    "        source = driver.page_source\n",
    "        f = open('all_orders/'+str(i) + '-' + rest_id+'.txt','w')\n",
    "        _=f.write(source)\n",
    "        _=f.close()\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse all htmls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_list = os.listdir('all_restaurants/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    rest_list.remove('.ipynb_checkpoints')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/anastasis/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "281it [00:07, 37.07it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for i,r in tqdm(enumerate(rest_list)):\n",
    "    \n",
    "    # Open\n",
    "    f =  open('all_restaurants/'+r,'r')\n",
    "\n",
    "    contents = f.read()\n",
    "    soup = BeautifulSoup(contents, 'lxml')\n",
    "\n",
    "    # Get restaurant data\n",
    "    drest = pd.Series(name=i)\n",
    "    fields = soup.findAll('div',{'class':'readonly_label'})\n",
    "    for field in fields:\n",
    "        drest.loc[re.sub('field-','',field['id'])] = field.text\n",
    "       \n",
    "    df = pd.concat([df,drest],axis=1,sort=False)\n",
    "df = df.T  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('stripeId',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the new list with the one previously scraped, to check for new entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = pd.read_pickle('Pickles/active_08_03.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New vs old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = df_old.loc[df_old['status'] == 'active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = df_new.loc[df_new['status'] == 'active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_new = [True if i not in df_old['uniqueId'].tolist() else False for i in act['uniqueId'].tolist() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "act.loc[filter_new].drop(['uniqueId'],axis=1).to_excel('restaurants_new.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract pending entries, in order to make concat and help them complete their registration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['test@test.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pend = df.loc[df['status']=='pending']\n",
    "# Remove test names\n",
    "pend = pend.loc[[False if e in to_drop else True for e in pend['email']]]\n",
    "\n",
    "# Remove VATs that have already been used\n",
    "pend = pend.loc[[False if e in act['piva'].tolist() else True for e in pend['piva']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pend.to_excel('pending.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a full list of all orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_list = os.listdir('all_orders/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    order_list.remove('.ipynb_checkpoints')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "do = pd.DataFrame()\n",
    "columns = ['id','last name','email','city','voucherCode','hash','price']\n",
    "for i,r in enumerate(order_list):\n",
    "    \n",
    "    # Open\n",
    "    f =  open('all_orders/'+r,'r')\n",
    "\n",
    "    contents = f.read()\n",
    "    soup = BeautifulSoup(contents, 'lxml')\n",
    "    \n",
    "    \n",
    "    data = []\n",
    "    table = soup.find('table')\n",
    "    table_body = table.find('tbody')\n",
    "\n",
    "    rows = table_body.find_all('tr')\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        data.append([ele for ele in cols if ele]) # Get rid of empty values\n",
    "\n",
    "    dord = pd.DataFrame(data,columns = columns)\n",
    "    dord['Restaurant'] = r\n",
    "\n",
    "    do = pd.concat([do,dord],axis=0,sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "do = do.drop(['voucherCode','hash'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "do['price'] = do['price'].astype('int64')/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "do['Restaurant'] = do['Restaurant'].apply(lambda x: re.sub('.txt','',re.split('-',x,maxsplit=1)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove a default restaurant\n",
    "do = do.loc[do['Restaurant'] != 'RS-5ebfbd70878d2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get links for extra data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need some extra information. So we'll scrape a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_link = 'https://control.saveoneseat.com/controlpanel/orders/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "do['Links'] = do.apply(lambda x:base_link + x['Restaurant'] + '/read/' + str(x['id']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get extra order data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [01:19,  4.18s/it]\n"
     ]
    }
   ],
   "source": [
    "for r,l,i in tqdm(zip(do['Restaurant'],do['Links'],do['id'])):\n",
    "    \n",
    "    time.sleep(1)\n",
    "    driver.get(l)\n",
    "    \n",
    "    time.sleep(2)\n",
    "    source = driver.page_source\n",
    "    f = open('order_details/'+str(i)+'.txt','w')\n",
    "    _=f.write(source)\n",
    "    _=f.close()\n",
    "    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table from extra data for orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_list = os.listdir('order_details/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    rest_list.remove('.ipynb_checkpoints')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/anastasis/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "19it [00:00, 54.95it/s]\n"
     ]
    }
   ],
   "source": [
    "d = pd.DataFrame()\n",
    "for i,r in tqdm(enumerate(rest_list)):\n",
    "    \n",
    "    # Open\n",
    "    f =  open('order_details/'+r,'r')\n",
    "\n",
    "    contents = f.read()\n",
    "    soup = BeautifulSoup(contents, 'lxml')\n",
    "\n",
    "    # Get restaurant data\n",
    "    drest = pd.Series(name=i)\n",
    "    fields = soup.findAll('div',{'class':'readonly_label'})\n",
    "    for field in fields:\n",
    "        drest.loc[re.sub('field-','',field['id'])] = field.text\n",
    "       \n",
    "    d = pd.concat([d,drest],axis=1,sort=False)\n",
    "d = d.T  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "do = d.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amend column names etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "do = pd.merge(df[['nome_rist','uniqueId']],do,how='right',right_on='restId',left_on='uniqueId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_old = ['nome_rist', 'uniqueId', 'email', 'name', 'surname', 'citta',\n",
    "       'codicefiscale', 'price', 'restName', 'paymentIntent', 'couponId',\n",
    "       'restId', 'stato']\n",
    "\n",
    "cols_new = ['name','Restaurant ID','email','first name','surname','city',\n",
    "       'codicefiscale', 'price', 'restName', 'paymentIntent', 'couponId',\n",
    "       'restId', 'status']\n",
    "\n",
    "cols_to_keep =  ['name','Restaurant ID','email','surname','city', 'price','status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "do.columns = pd.DataFrame(do.columns).replace(cols_old,cols_new)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "do = do.reindex(cols_to_keep,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "do['price'] = do['price'].astype('int64')/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group offers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare some aggregated output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_rest = do.groupby(['Restaurant ID','name'])['price'].agg([pd.Series.count,sum]).\\\n",
    "                        rename(columns = {'count':'Total No. Vouchers','sum':'Total Value'}).sort_values(by='Total Value',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_offer = do.groupby(['Coca-Cola Offer'])['price'].agg([pd.Series.count,sum]).\\\n",
    "                        rename(columns = {'count':'Total No. Vouchers','sum':'Total Value'}).sort_values(by='Total Value',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_useage = do.groupby(['status'])['price'].agg([pd.Series.count,sum]).\\\n",
    "                        rename(columns = {'count':'Total No. Vouchers','sum':'Total Value'}).sort_values(by='Total Value',ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '_08_27'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('Pickles/all_restaurants'+date+'.pkl')\n",
    "act.to_pickle('Pickles/active'+date+'.pkl')\n",
    "pend.to_pickle('Pickles/pending'+date+'.pkl')\n",
    "do.to_pickle('Pickles/orders'+date+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_excel({'By restaurant':by_rest,\n",
    "            'By offer':by_offer,\n",
    "            'By useage':by_useage},'Orders.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
